{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seasonal Trading Plan Project\n",
    "### This project seeks to figure out which stocks consistently go up over 30, 60 or 90 day periods, year after year, at least 80% of the time. It turns out there are many of them.\n",
    "\n",
    "In this notebook, I created a process to download full historical EOD price data on each of the S&P 500 index components and analyze the historical patterns to find situations where seasonal trends can be taken advantage of over the course of a year.\n",
    "\n",
    "For each stock, I calculated the following statistics:\n",
    "\n",
    "Holding Period:  The number of days held in each rolling period - 30, 60 and 90 days each.\n",
    "\n",
    "% Up Rows:  The percentage of rolling periods where, each year, the stock went up at least 80% of the time.\n",
    "\n",
    "Avg Up Return:  The average return for each rolling period where the return was positive.\n",
    "\n",
    "Avg Up StDev: The standard deviation of return for each rolling period where the return was positive. This means that the expected return should be within this +/- range from the average 67% of the time.\n",
    "\n",
    "% Downside:  The expected average return minus the standard deviation. This means that you should at least exceed this return 67% of the time. This could provide guidance for setting stop-loss levels.\n",
    "\n",
    "Least Pain Pt:  The time interval that offers the best case 67% downside within the sweet spot period. This is used to pinpoint the lowest risk time frame.\n",
    "\n",
    "Best Begin Date:  The recommended entry date for best risk/reward scenario.\n",
    "\n",
    "Best End Date:  The recommended exit date for best risk/reward scenario.\n",
    "\n",
    "Max Consec 80%+:  The longest consecutive number of rolling periods above 80% up years. You want to see more that a few consecutive up years over the threshold to provide assurance that the trend is robust.\n",
    "\n",
    "Total Years:  The number of years of historical data available for each stock. I filtered for stocks with 10+ years of history."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import yfinance as yf\n",
    "from pandas_datareader import data as pdr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the path to where I store this notebook and downloaded files. You need to change this to your convenient\n",
    "# spot on your own hard drive.\n",
    "\n",
    "my_path = '/Users/bnsheehy/Documents/Investments/Seasonal_Analyses/Python'\n",
    "threshold = 0.80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_sp500_tickers = my_path + \"/SP500_TickerList.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Symbol</th>\n",
       "      <th>Company Name</th>\n",
       "      <th>GICS Sector</th>\n",
       "      <th>GICS Sub Industry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A</td>\n",
       "      <td>Agilent Technologies Inc</td>\n",
       "      <td>Health Care</td>\n",
       "      <td>Health Care Equipment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AAL</td>\n",
       "      <td>American Airlines Group</td>\n",
       "      <td>Industrials</td>\n",
       "      <td>Airlines</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AAP</td>\n",
       "      <td>Advance Auto Parts</td>\n",
       "      <td>Consumer Discretionary</td>\n",
       "      <td>Automotive Retail</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>Apple Inc.</td>\n",
       "      <td>Information Technology</td>\n",
       "      <td>Technology Hardware, Storage &amp; Peripherals</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ABBV</td>\n",
       "      <td>Rickers</td>\n",
       "      <td>Health Care</td>\n",
       "      <td>Pharmaceuticals</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Symbol              Company Name             GICS Sector  \\\n",
       "0      A  Agilent Technologies Inc             Health Care   \n",
       "1    AAL   American Airlines Group             Industrials   \n",
       "2    AAP        Advance Auto Parts  Consumer Discretionary   \n",
       "3   AAPL                Apple Inc.  Information Technology   \n",
       "4   ABBV                   Rickers             Health Care   \n",
       "\n",
       "                            GICS Sub Industry  \n",
       "0                       Health Care Equipment  \n",
       "1                                    Airlines  \n",
       "2                           Automotive Retail  \n",
       "3  Technology Hardware, Storage & Peripherals  \n",
       "4                             Pharmaceuticals  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Upload a list of the S&P 500 components downloaded from Yahoo.\n",
    "\n",
    "df_sp500_tickers = pd.read_csv (file_sp500_tickers)\n",
    "df_sp500_tickers.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- FIS: Error occurred while retrieving timeseries from Redis, keys: [RedisKey [key=FIS, cluster=finance]]\n"
     ]
    }
   ],
   "source": [
    "# This module loops through the S&P 500 tickers, downloads the data from Yahoo and creates a separate CSV \n",
    "# file of historical data for each ticker (e.g. AAPL.csv).\n",
    "# Skip this routine if you already have the CSV files available.\n",
    "\n",
    "for index, ticker in df_sp500_tickers.iterrows():\n",
    "    my_ticker = ticker['Symbol']\n",
    "    \n",
    "    yf_ticker = yf.Ticker(my_ticker)\n",
    "    data = yf_ticker.history(period=\"max\")\n",
    "    df = pd.DataFrame(data)\n",
    "    df.reset_index(level=0, inplace=True)\n",
    "    df['Symbol'] = my_ticker\n",
    "    df = df[['Symbol','Date','Close']]\n",
    "    df.to_csv(path_or_buf = my_path + \"/data/\" + my_ticker +\".csv\", index=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>my_ticker</th>\n",
       "      <th>hold_per</th>\n",
       "      <th>pct_uprows</th>\n",
       "      <th>max_up_return</th>\n",
       "      <th>min_up_return</th>\n",
       "      <th>avg_up_return</th>\n",
       "      <th>stdev_up_return</th>\n",
       "      <th>pct_downside</th>\n",
       "      <th>least_pain_pt</th>\n",
       "      <th>total_years</th>\n",
       "      <th>max_consec_beat</th>\n",
       "      <th>best_buy_date</th>\n",
       "      <th>best_sell_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [my_ticker, hold_per, pct_uprows, max_up_return, min_up_return, avg_up_return, stdev_up_return, pct_downside, least_pain_pt, total_years, max_consec_beat, best_buy_date, best_sell_date]\n",
       "Index: []"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creates the dataframe container for the stats data.\n",
    "\n",
    "df_tradelist = pd.DataFrame(index=[], columns=['my_ticker', 'hold_per', 'pct_uprows', 'max_up_return', 'min_up_return', 'avg_up_return', 'stdev_up_return', 'pct_downside', 'least_pain_pt', 'total_years', 'max_consec_beat', 'best_buy_date', 'best_sell_date'])\n",
    "\n",
    "df_tradelist.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This module grabs each ticker file, transforms it and calculates the statistics needed for a 90 day holding period.\n",
    "\n",
    "def calc_3month_returns():\n",
    "    \n",
    "    global df_tradelist\n",
    "    global threshold\n",
    "    hold_per=\"3 Mos\"\n",
    "    \n",
    "    # Convert prices to 3 month returns based on 20 trading days per month.\n",
    "    dfr = df.pct_change(periods=60)\n",
    "    dfr.reset_index(level=0, inplace=True)\n",
    "    dfr.rename(columns={'Close':'Returns'}, inplace=True)\n",
    "    dfr = dfr.round(4)\n",
    "    \n",
    "    # Separate out the date column into separate month, year and day values.\n",
    "    dfr['Month'] = pd.DatetimeIndex(dfr['Date']).month\n",
    "    dfr['Day'] = pd.DatetimeIndex(dfr['Date']).day\n",
    "    dfr['Year'] = pd.DatetimeIndex(dfr['Date']).year\n",
    "    dfr['M-D'] = dfr['Month'].astype(str)+'-'+dfr['Day'].astype(str)\n",
    "    pd.set_option('display.max_rows', len(dfr))\n",
    "\n",
    "    # Pivot the table to show years across the top and Month-Day values in the first column on the left.\n",
    "    dfr_pivot = dfr.pivot(index='M-D', columns='Year', values='Returns')\n",
    "    dfr_pivot.reset_index(level=0, inplace=True)\n",
    "    dfr_pivot = pd.DataFrame(dfr_pivot)\n",
    "    dfr_pivot.columns.name=\"Index\"\n",
    "\n",
    "    # The pivot operation created empty cells for weekends and holiday, so I filled them with EOD values from\n",
    "    # the previous trading day.\n",
    "    dfr_pivot.fillna(method='ffill', inplace=True)\n",
    "\n",
    "    # Add additional calculated columns to facilitate statistic calculations for each stock.\n",
    "    dfr_pivot['YearCount'] = dfr_pivot.count(axis=1, numeric_only=True)\n",
    "    dfr_pivot['UpCount'] = dfr_pivot[dfr_pivot.iloc[:,1:len(dfr_pivot.columns)] > 0].count(axis=1)-1\n",
    "    dfr_pivot['DownCount'] = dfr_pivot[dfr_pivot.iloc[:,1:len(dfr_pivot.columns)] < 0].count(axis=1)\n",
    "    dfr_pivot['PctUp'] = dfr_pivot['UpCount']/dfr_pivot['YearCount']\n",
    "    dfr_pivot['PctDown'] = dfr_pivot['DownCount']/dfr_pivot['YearCount']\n",
    "    dfr_pivot['AvgReturn'] = dfr_pivot.iloc[:,1:len(dfr_pivot.columns)-5].mean(axis=1)\n",
    "    dfr_pivot['StDevReturns'] = dfr_pivot.iloc[:,1:len(dfr_pivot.columns)-6].std(axis=1)\n",
    "    dfr_pivot['67PctDownside'] = dfr_pivot['AvgReturn']-dfr_pivot['StDevReturns']\n",
    "    dfr_pivot['MaxReturn'] = dfr_pivot.iloc[:,1:len(dfr_pivot.columns)-8].max(axis=1)\n",
    "    dfr_pivot['MinReturn'] = dfr_pivot.iloc[:,1:len(dfr_pivot.columns)-9].min(axis=1)\n",
    "\n",
    "    # Add a fictional date column in Python date/time format so the table can be sorted by date. Then sort by Date.\n",
    "    dfr_pivot['Date'] = '2000-' + dfr_pivot['M-D'].astype(str)\n",
    "    dfr_pivot['Date'] = pd.to_datetime(dfr_pivot['Date'], infer_datetime_format=True)\n",
    "    dfr_pivot.sort_values(by='Date',ascending=True, inplace=True)\n",
    "    \n",
    "    # Reset the index and round the float values to 4 decimals.\n",
    "    dfr_pivot.reset_index(inplace=True)\n",
    "    dfr_pivot = dfr_pivot.round(4)\n",
    "    \n",
    "    # Export the final pivot table to CSV for further research later.\n",
    "    dfr_pivot.to_csv(path_or_buf = my_path + \"/data/\" + my_ticker + \"_dfr_pivot_3mo.csv\", index=False)\n",
    "\n",
    "    # Calculate the trading statistics for the rolling holding periods for the stock.\n",
    "    pct_uprows = (dfr_pivot.loc[dfr_pivot['PctUp'] > threshold, 'PctUp'].count() / dfr_pivot.loc[:, 'PctUp'].count()).astype(float).round(4)\n",
    "    max_up_return = dfr_pivot.loc[dfr_pivot['PctUp'] > threshold, 'MaxReturn'].max()\n",
    "    min_up_return = dfr_pivot.loc[dfr_pivot['PctUp'] > threshold, 'MinReturn'].min()\n",
    "    avg_up_return = dfr_pivot.loc[dfr_pivot['PctUp'] > 0, 'AvgReturn'].mean()\n",
    "    avg_up_return = np.float64(avg_up_return).round(4)\n",
    "    stdev_up_return = dfr_pivot.loc[dfr_pivot['PctUp'] > 0, 'StDevReturns'].mean()\n",
    "    stdev_up_return = np.float64(stdev_up_return).round(4)\n",
    "    pct_downside = (avg_up_return - stdev_up_return)\n",
    "    pct_downside = np.float64(pct_downside).round(4)\n",
    "    least_pain_pt = dfr_pivot.loc[dfr_pivot['PctUp'] > threshold, '67PctDownside'].max()\n",
    "    total_years = dfr_pivot['YearCount'].max()\n",
    "    \n",
    "    n_consec = 0\n",
    "    max_n_consec = 0\n",
    "\n",
    "    for x in dfr_pivot['PctUp']:\n",
    "        if (x > threshold):\n",
    "            n_consec += 1\n",
    "        else: # check for new max, then start again from 1\n",
    "            max_n_consec = max(n_consec, max_n_consec)\n",
    "            n_consec = 1\n",
    "\n",
    "    max_consec_beat = max_n_consec\n",
    "\n",
    "    try:\n",
    "        best_sell_date = dfr_pivot.loc[dfr_pivot['67PctDownside'] == least_pain_pt, 'M-D'].iloc[0]\n",
    "    except:\n",
    "        best_sell_date = \"nan\"\n",
    "\n",
    "    try:\n",
    "        row = dfr_pivot.loc[dfr_pivot['M-D'] == best_sell_date, 'M-D'].index[0]-90\n",
    "        col = dfr_pivot.columns.get_loc('M-D')\n",
    "        best_buy_date = dfr_pivot.iloc[row,col]\n",
    "    except:\n",
    "        best_buy_date = \"nan\"\n",
    "\n",
    "    # Create the array of stat values and append it to the recommended trade list.\n",
    "    statsdata = np.array([my_ticker, hold_per, pct_uprows, max_up_return, min_up_return, avg_up_return, stdev_up_return, pct_downside, least_pain_pt, total_years, max_consec_beat, best_buy_date, best_sell_date])\n",
    "    \n",
    "    df_tradelist = df_tradelist.append(dict(zip(df_tradelist.columns, statsdata)), ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This module grabs each ticker file, transforms it and calculates the statistics needed for a 60 day holding period.\n",
    "\n",
    "def calc_2month_returns():\n",
    "    \n",
    "    global df_tradelist\n",
    "    global threshold\n",
    "    hold_per=\"2 Mos\"\n",
    "\n",
    "    # Convert prices to 3 month returns based on 20 trading days per month.\n",
    "    dfr = df.pct_change(periods=40)\n",
    "    dfr.reset_index(level=0, inplace=True)\n",
    "    dfr.rename(columns={'Close':'Returns'}, inplace=True)\n",
    "    dfr = dfr.round(4)\n",
    "    \n",
    "    # Separate out the date column into separate month, year and day values.\n",
    "    dfr['Month'] = pd.DatetimeIndex(dfr['Date']).month\n",
    "    dfr['Day'] = pd.DatetimeIndex(dfr['Date']).day\n",
    "    dfr['Year'] = pd.DatetimeIndex(dfr['Date']).year\n",
    "    dfr['M-D'] = dfr['Month'].astype(str)+'-'+dfr['Day'].astype(str)\n",
    "    pd.set_option('display.max_rows', len(dfr))\n",
    "\n",
    "    # Pivot the table to show years across the top and Month-Day values in the first column on the left.\n",
    "    dfr_pivot = dfr.pivot(index='M-D', columns='Year', values='Returns')\n",
    "    dfr_pivot.reset_index(level=0, inplace=True)\n",
    "    dfr_pivot = pd.DataFrame(dfr_pivot)\n",
    "    dfr_pivot.columns.name=\"Index\"\n",
    "\n",
    "    # The pivot operation created empty cells for weekends and holiday, so I filled them with EOD values from\n",
    "    # the previous trading day.\n",
    "    dfr_pivot.fillna(method='ffill', inplace=True)\n",
    "\n",
    "    # Add additional calculated columns to facilitate statistic calculations for each stock.\n",
    "    dfr_pivot['YearCount'] = dfr_pivot.count(axis=1, numeric_only=True)\n",
    "    dfr_pivot['UpCount'] = dfr_pivot[dfr_pivot.iloc[:,1:len(dfr_pivot.columns)] > 0].count(axis=1)-1\n",
    "    dfr_pivot['DownCount'] = dfr_pivot[dfr_pivot.iloc[:,1:len(dfr_pivot.columns)] < 0].count(axis=1)\n",
    "    dfr_pivot['PctUp'] = dfr_pivot['UpCount']/dfr_pivot['YearCount']\n",
    "    dfr_pivot['PctDown'] = dfr_pivot['DownCount']/dfr_pivot['YearCount']\n",
    "    dfr_pivot['AvgReturn'] = dfr_pivot.iloc[:,1:len(dfr_pivot.columns)-5].mean(axis=1)\n",
    "    dfr_pivot['StDevReturns'] = dfr_pivot.iloc[:,1:len(dfr_pivot.columns)-6].std(axis=1)\n",
    "    dfr_pivot['67PctDownside'] = dfr_pivot['AvgReturn']-dfr_pivot['StDevReturns']\n",
    "    dfr_pivot['MaxReturn'] = dfr_pivot.iloc[:,1:len(dfr_pivot.columns)-8].max(axis=1)\n",
    "    dfr_pivot['MinReturn'] = dfr_pivot.iloc[:,1:len(dfr_pivot.columns)-9].min(axis=1)\n",
    "\n",
    "    # Add a fictional date column in Python date/time format so the table can be sorted by date. Then sort by Date.\n",
    "    dfr_pivot['Date'] = '2000-' + dfr_pivot['M-D'].astype(str)\n",
    "    dfr_pivot['Date'] = pd.to_datetime(dfr_pivot['Date'], infer_datetime_format=True)\n",
    "    dfr_pivot.sort_values(by='Date',ascending=True, inplace=True)\n",
    "    \n",
    "    # Reset the index and round the float values to 4 decimals.\n",
    "    dfr_pivot.reset_index(inplace=True)\n",
    "    dfr_pivot = dfr_pivot.round(4)\n",
    "    \n",
    "    # Export the final pivot table to CSV for further research later.\n",
    "    dfr_pivot.to_csv(path_or_buf = my_path + \"/data/\" + my_ticker + \"_dfr_pivot_2mo.csv\", index=False)\n",
    "\n",
    "    # Calculate the trading statistics for the rolling holding periods for the stock.\n",
    "    pct_uprows = (dfr_pivot.loc[dfr_pivot['PctUp'] > threshold, 'PctUp'].count() / dfr_pivot.loc[:, 'PctUp'].count()).astype(float).round(4)\n",
    "    max_up_return = dfr_pivot.loc[dfr_pivot['PctUp'] > threshold, 'MaxReturn'].max()\n",
    "    min_up_return = dfr_pivot.loc[dfr_pivot['PctUp'] > threshold, 'MinReturn'].min()\n",
    "    avg_up_return = dfr_pivot.loc[dfr_pivot['PctUp'] > 0, 'AvgReturn'].mean()\n",
    "    avg_up_return = np.float64(avg_up_return).round(4)\n",
    "    stdev_up_return = dfr_pivot.loc[dfr_pivot['PctUp'] > 0, 'StDevReturns'].mean()\n",
    "    stdev_up_return = np.float64(stdev_up_return).round(4)\n",
    "    pct_downside = (avg_up_return - stdev_up_return)\n",
    "    pct_downside = np.float64(pct_downside).round(4)\n",
    "    least_pain_pt = dfr_pivot.loc[dfr_pivot['PctUp'] > threshold, '67PctDownside'].max()\n",
    "    total_years = dfr_pivot['YearCount'].max()\n",
    "    \n",
    "    n_consec = 0\n",
    "    max_n_consec = 0\n",
    "\n",
    "    for x in dfr_pivot['PctUp']:\n",
    "        if (x > threshold):\n",
    "            n_consec += 1\n",
    "        else: # check for new max, then start again from 1\n",
    "            max_n_consec = max(n_consec, max_n_consec)\n",
    "            n_consec = 1\n",
    "\n",
    "    max_consec_beat = max_n_consec\n",
    "\n",
    "    try:\n",
    "        best_sell_date = dfr_pivot.loc[dfr_pivot['67PctDownside'] == least_pain_pt, 'M-D'].iloc[0]\n",
    "    except:\n",
    "        best_sell_date = \"nan\"\n",
    "\n",
    "    try:\n",
    "        row = dfr_pivot.loc[dfr_pivot['M-D'] == best_sell_date, 'M-D'].index[0]-60\n",
    "        col = dfr_pivot.columns.get_loc('M-D')\n",
    "        best_buy_date = dfr_pivot.iloc[row,col]\n",
    "    except:\n",
    "        best_buy_date = \"nan\"\n",
    "\n",
    "    # Create the array of stat values and append it to the recommended trade list.\n",
    "    statsdata = np.array([my_ticker, hold_per, pct_uprows, max_up_return, min_up_return, avg_up_return, stdev_up_return, pct_downside, least_pain_pt, total_years, max_consec_beat, best_buy_date, best_sell_date])\n",
    "    \n",
    "    df_tradelist = df_tradelist.append(dict(zip(df_tradelist.columns, statsdata)), ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This module grabs each ticker file, transforms it and calculates the statistics needed for a 30 day holding period.\n",
    "\n",
    "def calc_1month_returns():\n",
    "    \n",
    "    global df_tradelist\n",
    "    global threshold\n",
    "    hold_per=\"1 Mo\"\n",
    "\n",
    "    # Convert prices to 3 month returns based on 20 trading days per month.\n",
    "    dfr = df.pct_change(periods=20)\n",
    "    dfr.reset_index(level=0, inplace=True)\n",
    "    dfr.rename(columns={'Close':'Returns'}, inplace=True)\n",
    "    dfr = dfr.round(4)\n",
    "    \n",
    "    # Separate out the date column into separate month, year and day values.\n",
    "    dfr['Month'] = pd.DatetimeIndex(dfr['Date']).month\n",
    "    dfr['Day'] = pd.DatetimeIndex(dfr['Date']).day\n",
    "    dfr['Year'] = pd.DatetimeIndex(dfr['Date']).year\n",
    "    dfr['M-D'] = dfr['Month'].astype(str)+'-'+dfr['Day'].astype(str)\n",
    "\n",
    "    # Pivot the table to show years across the top and Month-Day values in the first column on the left.\n",
    "    dfr_pivot = dfr.pivot(index='M-D', columns='Year', values='Returns')\n",
    "    dfr_pivot.reset_index(level=0, inplace=True)\n",
    "    dfr_pivot = pd.DataFrame(dfr_pivot)\n",
    "    dfr_pivot.columns.name=\"Index\"\n",
    "\n",
    "    # The pivot operation created empty cells for weekends and holiday, so I filled them with EOD values from\n",
    "    # the previous trading day.\n",
    "    dfr_pivot.fillna(method='ffill', inplace=True)\n",
    "\n",
    "    # Add additional calculated columns to facilitate statistic calculations for each stock.\n",
    "    dfr_pivot['YearCount'] = dfr_pivot.count(axis=1, numeric_only=True)\n",
    "    dfr_pivot['UpCount'] = dfr_pivot[dfr_pivot.iloc[:,1:len(dfr_pivot.columns)] > 0].count(axis=1)-1\n",
    "    dfr_pivot['DownCount'] = dfr_pivot[dfr_pivot.iloc[:,1:len(dfr_pivot.columns)] < 0].count(axis=1)\n",
    "    dfr_pivot['PctUp'] = dfr_pivot['UpCount']/dfr_pivot['YearCount']\n",
    "    dfr_pivot['PctDown'] = dfr_pivot['DownCount']/dfr_pivot['YearCount']\n",
    "    dfr_pivot['AvgReturn'] = dfr_pivot.iloc[:,1:len(dfr_pivot.columns)-5].mean(axis=1)\n",
    "    dfr_pivot['StDevReturns'] = dfr_pivot.iloc[:,1:len(dfr_pivot.columns)-6].std(axis=1)\n",
    "    dfr_pivot['67PctDownside'] = dfr_pivot['AvgReturn']-dfr_pivot['StDevReturns']\n",
    "    dfr_pivot['MaxReturn'] = dfr_pivot.iloc[:,1:len(dfr_pivot.columns)-8].max(axis=1)\n",
    "    dfr_pivot['MinReturn'] = dfr_pivot.iloc[:,1:len(dfr_pivot.columns)-9].min(axis=1)\n",
    "\n",
    "    # Add a fictional date column in Python date/time format so the table can be sorted by date. Then sort by Date.\n",
    "    dfr_pivot['Date'] = '2000-' + dfr_pivot['M-D'].astype(str)\n",
    "    dfr_pivot['Date'] = pd.to_datetime(dfr_pivot['Date'], infer_datetime_format=True)\n",
    "    dfr_pivot.sort_values(by='Date',ascending=True, inplace=True)\n",
    "    \n",
    "    # Reset the index and round the float values to 4 decimals.\n",
    "    dfr_pivot.reset_index(inplace=True)\n",
    "    dfr_pivot = dfr_pivot.round(4)\n",
    "    \n",
    "    # Export the final pivot table to CSV for further research later.\n",
    "    dfr_pivot.to_csv(path_or_buf = my_path + \"/data/\" + my_ticker + \"_dfr_pivot_1mo.csv\", index=False)\n",
    "\n",
    "    # Calculate the trading statistics for the rolling holding periods for the stock.\n",
    "    pct_uprows = (dfr_pivot.loc[dfr_pivot['PctUp'] > threshold, 'PctUp'].count() / dfr_pivot.loc[:, 'PctUp'].count()).astype(float).round(4)\n",
    "    max_up_return = dfr_pivot.loc[dfr_pivot['PctUp'] > threshold, 'MaxReturn'].max()\n",
    "    min_up_return = dfr_pivot.loc[dfr_pivot['PctUp'] > threshold, 'MinReturn'].min()\n",
    "    avg_up_return = dfr_pivot.loc[dfr_pivot['PctUp'] > 0, 'AvgReturn'].mean()\n",
    "    avg_up_return = np.float64(avg_up_return).round(4)\n",
    "    stdev_up_return = dfr_pivot.loc[dfr_pivot['PctUp'] > 0, 'StDevReturns'].mean()\n",
    "    stdev_up_return = np.float64(stdev_up_return).round(4)\n",
    "    pct_downside = (avg_up_return - stdev_up_return)\n",
    "    pct_downside = np.float64(pct_downside).round(4)\n",
    "    least_pain_pt = dfr_pivot.loc[dfr_pivot['PctUp'] > threshold, '67PctDownside'].max()\n",
    "    total_years = dfr_pivot['YearCount'].max()\n",
    "\n",
    "    n_consec = 0\n",
    "    max_n_consec = 0\n",
    "\n",
    "    for x in dfr_pivot['PctUp']:\n",
    "        if (x > threshold):\n",
    "            n_consec += 1\n",
    "        else: # check for new max, then start again from 1\n",
    "            max_n_consec = max(n_consec, max_n_consec)\n",
    "            n_consec = 1\n",
    "\n",
    "    max_consec_beat = max_n_consec\n",
    "\n",
    "    try:\n",
    "        best_sell_date = dfr_pivot.loc[dfr_pivot['67PctDownside'] == least_pain_pt, 'M-D'].iloc[0]\n",
    "    except:\n",
    "        best_sell_date = \"nan\"\n",
    "\n",
    "    try:\n",
    "        row = dfr_pivot.loc[dfr_pivot['M-D'] == best_sell_date, 'M-D'].index[0]-30\n",
    "        col = dfr_pivot.columns.get_loc('M-D')\n",
    "        best_buy_date = dfr_pivot.iloc[row,col]\n",
    "    except:\n",
    "        best_buy_date = \"nan\"\n",
    "\n",
    "    # Create the array of stat values and append it to the recommended trade list.\n",
    "    statsdata = np.array([my_ticker, hold_per, pct_uprows, max_up_return, min_up_return, avg_up_return, stdev_up_return, pct_downside, least_pain_pt, total_years, max_consec_beat, best_buy_date, best_sell_date])\n",
    "       \n",
    "    df_tradelist = df_tradelist.append(dict(zip(df_tradelist.columns, statsdata)), ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bnsheehy/opt/miniconda3/lib/python3.7/site-packages/ipykernel_launcher.py:46: RuntimeWarning: invalid value encountered in long_scalars\n",
      "/Users/bnsheehy/opt/miniconda3/lib/python3.7/site-packages/ipykernel_launcher.py:45: RuntimeWarning: invalid value encountered in long_scalars\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Read CSV files by ticker, transform and extract stats from each one.\n",
    "\n",
    "for index, ticker in df_sp500_tickers.iterrows():\n",
    "    my_ticker = ticker['Symbol']\n",
    "\n",
    "    df = pd.read_csv (my_path + \"/data/\" + my_ticker + \".csv\")\n",
    "    df.set_index('Date', inplace=True)\n",
    "    df = df['Close']\n",
    "    df = pd.DataFrame(df, columns=['Close'])\n",
    "    \n",
    "    calc_1month_returns()\n",
    "    \n",
    "    calc_2month_returns()\n",
    "    \n",
    "    calc_3month_returns()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>my_ticker</th>\n",
       "      <th>hold_per</th>\n",
       "      <th>pct_uprows</th>\n",
       "      <th>max_up_return</th>\n",
       "      <th>min_up_return</th>\n",
       "      <th>avg_up_return</th>\n",
       "      <th>stdev_up_return</th>\n",
       "      <th>pct_downside</th>\n",
       "      <th>least_pain_pt</th>\n",
       "      <th>total_years</th>\n",
       "      <th>max_consec_beat</th>\n",
       "      <th>best_buy_date</th>\n",
       "      <th>best_sell_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1499</th>\n",
       "      <td>YUM</td>\n",
       "      <td>3 Mos</td>\n",
       "      <td>0.1377</td>\n",
       "      <td>0.5091</td>\n",
       "      <td>-0.2379</td>\n",
       "      <td>0.0344</td>\n",
       "      <td>0.1169</td>\n",
       "      <td>-0.0825</td>\n",
       "      <td>0.0246</td>\n",
       "      <td>24</td>\n",
       "      <td>39</td>\n",
       "      <td>2-6</td>\n",
       "      <td>5-6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1500</th>\n",
       "      <td>ZBH</td>\n",
       "      <td>1 Mo</td>\n",
       "      <td>0.0303</td>\n",
       "      <td>0.177</td>\n",
       "      <td>-0.1373</td>\n",
       "      <td>0.0114</td>\n",
       "      <td>0.065</td>\n",
       "      <td>-0.0536</td>\n",
       "      <td>-0.0048</td>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>12-16</td>\n",
       "      <td>1-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1501</th>\n",
       "      <td>ZBH</td>\n",
       "      <td>2 Mos</td>\n",
       "      <td>0.0771</td>\n",
       "      <td>0.297</td>\n",
       "      <td>-0.1404</td>\n",
       "      <td>0.0238</td>\n",
       "      <td>0.0915</td>\n",
       "      <td>-0.0677</td>\n",
       "      <td>0.0092</td>\n",
       "      <td>20</td>\n",
       "      <td>7</td>\n",
       "      <td>12-21</td>\n",
       "      <td>2-21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1502</th>\n",
       "      <td>ZBH</td>\n",
       "      <td>3 Mos</td>\n",
       "      <td>0.0964</td>\n",
       "      <td>0.3439</td>\n",
       "      <td>-0.2127</td>\n",
       "      <td>0.0393</td>\n",
       "      <td>0.1146</td>\n",
       "      <td>-0.0753</td>\n",
       "      <td>0.0451</td>\n",
       "      <td>20</td>\n",
       "      <td>24</td>\n",
       "      <td>11-21</td>\n",
       "      <td>2-21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1503</th>\n",
       "      <td>ZION</td>\n",
       "      <td>1 Mo</td>\n",
       "      <td>0.0</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.0145</td>\n",
       "      <td>0.0917</td>\n",
       "      <td>-0.0772</td>\n",
       "      <td>nan</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1504</th>\n",
       "      <td>ZION</td>\n",
       "      <td>2 Mos</td>\n",
       "      <td>0.0028</td>\n",
       "      <td>0.356</td>\n",
       "      <td>-0.3402</td>\n",
       "      <td>0.0274</td>\n",
       "      <td>0.1285</td>\n",
       "      <td>-0.1011</td>\n",
       "      <td>-0.0786</td>\n",
       "      <td>41</td>\n",
       "      <td>2</td>\n",
       "      <td>1-17</td>\n",
       "      <td>3-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1505</th>\n",
       "      <td>ZION</td>\n",
       "      <td>3 Mos</td>\n",
       "      <td>0.0</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.0452</td>\n",
       "      <td>0.1586</td>\n",
       "      <td>-0.1134</td>\n",
       "      <td>nan</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1506</th>\n",
       "      <td>ZTS</td>\n",
       "      <td>1 Mo</td>\n",
       "      <td>0.1295</td>\n",
       "      <td>0.1859</td>\n",
       "      <td>-0.0897</td>\n",
       "      <td>0.028</td>\n",
       "      <td>0.0588</td>\n",
       "      <td>-0.0308</td>\n",
       "      <td>0.0126</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>5-11</td>\n",
       "      <td>6-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1507</th>\n",
       "      <td>ZTS</td>\n",
       "      <td>2 Mos</td>\n",
       "      <td>0.2314</td>\n",
       "      <td>0.2091</td>\n",
       "      <td>-0.1829</td>\n",
       "      <td>0.0486</td>\n",
       "      <td>0.0799</td>\n",
       "      <td>-0.0313</td>\n",
       "      <td>0.0285</td>\n",
       "      <td>8</td>\n",
       "      <td>24</td>\n",
       "      <td>10-30</td>\n",
       "      <td>12-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1508</th>\n",
       "      <td>ZTS</td>\n",
       "      <td>3 Mos</td>\n",
       "      <td>0.4793</td>\n",
       "      <td>0.243</td>\n",
       "      <td>-0.1952</td>\n",
       "      <td>0.0552</td>\n",
       "      <td>0.0817</td>\n",
       "      <td>-0.0265</td>\n",
       "      <td>0.0355</td>\n",
       "      <td>8</td>\n",
       "      <td>39</td>\n",
       "      <td>2-19</td>\n",
       "      <td>5-19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     my_ticker hold_per pct_uprows max_up_return min_up_return avg_up_return  \\\n",
       "1499       YUM    3 Mos     0.1377        0.5091       -0.2379        0.0344   \n",
       "1500       ZBH     1 Mo     0.0303         0.177       -0.1373        0.0114   \n",
       "1501       ZBH    2 Mos     0.0771         0.297       -0.1404        0.0238   \n",
       "1502       ZBH    3 Mos     0.0964        0.3439       -0.2127        0.0393   \n",
       "1503      ZION     1 Mo        0.0           nan           nan        0.0145   \n",
       "1504      ZION    2 Mos     0.0028         0.356       -0.3402        0.0274   \n",
       "1505      ZION    3 Mos        0.0           nan           nan        0.0452   \n",
       "1506       ZTS     1 Mo     0.1295        0.1859       -0.0897         0.028   \n",
       "1507       ZTS    2 Mos     0.2314        0.2091       -0.1829        0.0486   \n",
       "1508       ZTS    3 Mos     0.4793         0.243       -0.1952        0.0552   \n",
       "\n",
       "     stdev_up_return pct_downside least_pain_pt total_years max_consec_beat  \\\n",
       "1499          0.1169      -0.0825        0.0246          24              39   \n",
       "1500           0.065      -0.0536       -0.0048          20               5   \n",
       "1501          0.0915      -0.0677        0.0092          20               7   \n",
       "1502          0.1146      -0.0753        0.0451          20              24   \n",
       "1503          0.0917      -0.0772           nan          41               1   \n",
       "1504          0.1285      -0.1011       -0.0786          41               2   \n",
       "1505          0.1586      -0.1134           nan          41               1   \n",
       "1506          0.0588      -0.0308        0.0126           8               8   \n",
       "1507          0.0799      -0.0313        0.0285           8              24   \n",
       "1508          0.0817      -0.0265        0.0355           8              39   \n",
       "\n",
       "     best_buy_date best_sell_date  \n",
       "1499           2-6            5-6  \n",
       "1500         12-16           1-17  \n",
       "1501         12-21           2-21  \n",
       "1502         11-21           2-21  \n",
       "1503           nan            nan  \n",
       "1504          1-17           3-17  \n",
       "1505           nan            nan  \n",
       "1506          5-11           6-10  \n",
       "1507         10-30          12-30  \n",
       "1508          2-19           5-19  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preview the end of the trade list to see how many rows and make sure the data is showing up where it is supposed to.\n",
    "\n",
    "df_tradelist.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the trade list to a Pandas dataframe.\n",
    "df_tradelist = pd.DataFrame(df_tradelist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean it up by removing rows with NaN's and infinity values.\n",
    "df_tradelist.replace(\"inf\", np.nan, inplace=True)\n",
    "df_tradelist.dropna(inplace=True)\n",
    "df_tradelist = df_tradelist[~df_tradelist.max_up_return.str.contains(\"nan\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a final filtered and sorted recommended trade list.\n",
    "# I filtered out the stocks where the percentage of 80%+ up years was less than 1 out of 10. In other words,\n",
    "# with about 250 trading days in the year, each stock on the list needs to show at least 25 days where the holding\n",
    "# period ending on that day showed a gain for at least 4 out of 5 years surveyed.\n",
    "# Then I added a dummy date column, sorted by date, and the dropped the dummy column.\n",
    "\n",
    "df_tradelist['pct_uprows'] = df_tradelist['pct_uprows'].astype('Float64')\n",
    "df_tradelist_fs = df_tradelist[(df_tradelist['pct_uprows'] > 0.1)].copy()\n",
    "\n",
    "\n",
    "df_tradelist_fs['Date'] = '2000-' + df_tradelist_fs['best_buy_date'].astype(str)\n",
    "df_tradelist_fs['Date'] = pd.to_datetime(df_tradelist_fs['Date'], infer_datetime_format=True)\n",
    "df_tradelist_fs.sort_values(by='Date',ascending=True, inplace=True)\n",
    "df_tradelist_fs.drop('Date', axis=1, inplace=True)\n",
    "df_tradelist_fs.drop_duplicates(subset=\"my_ticker\", keep='first', inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>my_ticker</th>\n",
       "      <th>hold_per</th>\n",
       "      <th>pct_uprows</th>\n",
       "      <th>max_up_return</th>\n",
       "      <th>min_up_return</th>\n",
       "      <th>avg_up_return</th>\n",
       "      <th>stdev_up_return</th>\n",
       "      <th>pct_downside</th>\n",
       "      <th>least_pain_pt</th>\n",
       "      <th>total_years</th>\n",
       "      <th>max_consec_beat</th>\n",
       "      <th>best_buy_date</th>\n",
       "      <th>best_sell_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>653</th>\n",
       "      <td>HCA</td>\n",
       "      <td>3 Mos</td>\n",
       "      <td>0.2452</td>\n",
       "      <td>0.396</td>\n",
       "      <td>-0.2151</td>\n",
       "      <td>0.0755</td>\n",
       "      <td>0.1393</td>\n",
       "      <td>-0.0638</td>\n",
       "      <td>0.0614</td>\n",
       "      <td>10</td>\n",
       "      <td>29</td>\n",
       "      <td>1-2</td>\n",
       "      <td>4-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1172</th>\n",
       "      <td>QRVO</td>\n",
       "      <td>3 Mos</td>\n",
       "      <td>0.3278</td>\n",
       "      <td>0.4512</td>\n",
       "      <td>-0.3229</td>\n",
       "      <td>0.1031</td>\n",
       "      <td>0.2309</td>\n",
       "      <td>-0.1278</td>\n",
       "      <td>0.1053</td>\n",
       "      <td>6</td>\n",
       "      <td>63</td>\n",
       "      <td>1-2</td>\n",
       "      <td>4-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>668</th>\n",
       "      <td>HII</td>\n",
       "      <td>3 Mos</td>\n",
       "      <td>0.3664</td>\n",
       "      <td>0.3715</td>\n",
       "      <td>-0.3056</td>\n",
       "      <td>0.0892</td>\n",
       "      <td>0.1357</td>\n",
       "      <td>-0.0465</td>\n",
       "      <td>0.1076</td>\n",
       "      <td>10</td>\n",
       "      <td>63</td>\n",
       "      <td>1-2</td>\n",
       "      <td>4-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>971</th>\n",
       "      <td>MSCI</td>\n",
       "      <td>3 Mos</td>\n",
       "      <td>0.2424</td>\n",
       "      <td>0.5458</td>\n",
       "      <td>-0.2672</td>\n",
       "      <td>0.067</td>\n",
       "      <td>0.14</td>\n",
       "      <td>-0.073</td>\n",
       "      <td>0.0405</td>\n",
       "      <td>13</td>\n",
       "      <td>22</td>\n",
       "      <td>1-4</td>\n",
       "      <td>4-3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>590</th>\n",
       "      <td>FTNT</td>\n",
       "      <td>3 Mos</td>\n",
       "      <td>0.3857</td>\n",
       "      <td>0.5178</td>\n",
       "      <td>-0.3961</td>\n",
       "      <td>0.1106</td>\n",
       "      <td>0.2099</td>\n",
       "      <td>-0.0993</td>\n",
       "      <td>0.1261</td>\n",
       "      <td>11</td>\n",
       "      <td>71</td>\n",
       "      <td>1-4</td>\n",
       "      <td>4-3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     my_ticker hold_per  pct_uprows max_up_return min_up_return avg_up_return  \\\n",
       "653        HCA    3 Mos      0.2452         0.396       -0.2151        0.0755   \n",
       "1172      QRVO    3 Mos      0.3278        0.4512       -0.3229        0.1031   \n",
       "668        HII    3 Mos      0.3664        0.3715       -0.3056        0.0892   \n",
       "971       MSCI    3 Mos      0.2424        0.5458       -0.2672         0.067   \n",
       "590       FTNT    3 Mos      0.3857        0.5178       -0.3961        0.1106   \n",
       "\n",
       "     stdev_up_return pct_downside least_pain_pt total_years max_consec_beat  \\\n",
       "653           0.1393      -0.0638        0.0614          10              29   \n",
       "1172          0.2309      -0.1278        0.1053           6              63   \n",
       "668           0.1357      -0.0465        0.1076          10              63   \n",
       "971             0.14       -0.073        0.0405          13              22   \n",
       "590           0.2099      -0.0993        0.1261          11              71   \n",
       "\n",
       "     best_buy_date best_sell_date  \n",
       "653            1-2            4-1  \n",
       "1172           1-2            4-1  \n",
       "668            1-2            4-1  \n",
       "971            1-4            4-3  \n",
       "590            1-4            4-3  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preview the results. There should be between 50 and 100 stock trades on the final list.\n",
    "df_tradelist_fs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export the original and the filtered trade lists to CSV files for execution and/or further research if desired.\n",
    "df_tradelist.to_csv(path_or_buf = my_path + \"/df_tradelist.csv\", index=False)\n",
    "df_tradelist_fs.to_csv(path_or_buf = my_path + \"/df_tradelist_fs.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
